import math
import os
import time
from datetime import datetime

import pandas as pd
from sqlalchemy import select

from core.etl.dataloader.create_db_session import create_db_session
from core.web_requests.web_requests import make_get_request
from datamodels.digicher.entities import Institutions


def get_institution_openalex(name: str):
    time.sleep(0.1)
    return make_get_request(
        "https://api.openalex.org/institutions",
        params={
            "search": name,
            "select": "id,display_name,geo,display_name_alternatives",
            "mailto": "walter.ehrenberger@uni-jena.de",
        },
    )


def get_distance_in_meters(point1, point2):
    """
    @ Generated by Claude
    Calculate the great-circle distance between two points on Earth using the Haversine formula.

    Parameters:
    point1 (list): [latitude, longitude] of first point
    point2 (list): [latitude, longitude] of second point

    Returns:
    float: Distance between points in meters
    """
    R = 6371000  # Earth's radius in meters

    lat1, lng1 = point1
    lat2, lng2 = point2

    d_lat = (lat2 - lat1) * math.pi / 180
    d_lng = (lng2 - lng1) * math.pi / 180

    a = math.sin(d_lat / 2) * math.sin(d_lat / 2) + math.cos(
        lat1 * math.pi / 180
    ) * math.cos(lat2 * math.pi / 180) * math.sin(d_lng / 2) * math.sin(d_lng / 2)

    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    distance = R * c

    return distance


BATCH_SIZE = 50
OFFSET = 21200

# Create a timestamped filename
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_filename = f"openalex_geo_{timestamp}.csv"
file_exists = os.path.isfile(csv_filename)

session_factory = create_db_session()
with session_factory() as session:
    print(f"Starting the process at {timestamp}")
    print(f"Results will be saved to {csv_filename}")

    # Create DataFrame structure
    columns = [
        "i.id",
        "oa.id",
        "i.name",
        "oa.name",
        "i.geo",
        "oa.geo",
        "dist (m)",
        "matching_name",
    ]

    keep_going = True
    while keep_going:
        print(f"Processing batch with OFFSET = {OFFSET}")
        statement = select(Institutions).limit(BATCH_SIZE).offset(OFFSET)
        rows = session.execute(statement).all()

        # Empty dataframe for this batch
        batch_df = pd.DataFrame(columns=columns)

        for institution in rows:
            i = institution[0]
            results = get_institution_openalex(i.name.replace("!", "").replace("|", ""))

            if len(results["results"]) == 0:
                continue

            oa = results["results"][0]
            if i.address_geolocation:
                dist = get_distance_in_meters(
                    i.address_geolocation,
                    [float(oa["geo"]["latitude"]), float(oa["geo"]["longitude"])],
                )
            else:
                dist = ""

            if dist and float(dist) < 150:
                continue

            check_name = False
            if oa["display_name"].upper() == i.name.upper() or any(
                alt.upper() == i.name.upper()
                for alt in oa.get("display_name_alternatives", [])
            ):
                check_name = True

            batch_df.loc[len(batch_df)] = [
                i.id,
                oa["id"],
                i.name,
                oa["display_name"],
                (
                    f"{i.address_geolocation[0]}, {i.address_geolocation[1]}"
                    if i.address_geolocation
                    else ""
                ),
                f"{oa['geo']['latitude']}, {oa['geo']['longitude']}",
                round(dist, 0) if dist else "",
                check_name,
            ]

        # Append this batch to the CSV file
        if not batch_df.empty:
            batch_df.to_csv(
                csv_filename,
                mode="a",
                header=not file_exists,  # Only write header if file doesn't exist
                index=False,
                sep=";",
            )
            file_exists = True  # Set to true for subsequent batches
            print(f"Appended {len(batch_df)} rows to {csv_filename}")
        else:
            print("No matching results in this batch")

        # Check if we need to continue
        if len(rows) < BATCH_SIZE:
            keep_going = False
            print("Final batch processed, ending process")
        else:
            OFFSET += BATCH_SIZE

    print(f"Process completed. Results saved to {csv_filename}")

# compare!
# use csv to update database when happy
# Use EnrichmentMonitor!

# start with one small batch for testing
